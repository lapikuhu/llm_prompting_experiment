# Copy this file to .env and fill in your values.
# LLM_MODELS_JSON is a single JSON object keyed by model alias.
# Each entry requires: kind, provider, model, base_url, api_key
# kind: "generator" | "embedder" | "judge"
# provider: "openai_compatible"  (Ollama, OpenAI, Gemini-compat, etc.)

LLM_MODELS_JSON={
  "ollama-llama3": {
    "kind": "generator",
    "provider": "openai_compatible",
    "model": "llama3",
    "base_url": "http://localhost:11434",
    "api_key": "ollama"
  },
  "ollama-mistral": {
    "kind": "generator",
    "provider": "openai_compatible",
    "model": "mistral",
    "base_url": "http://localhost:11434",
    "api_key": "ollama"
  },
  "ollama-nomic-embed": {
    "kind": "embedder",
    "provider": "openai_compatible",
    "model": "nomic-embed-text",
    "base_url": "http://localhost:11434",
    "api_key": "ollama"
  },
  "ollama-judge": {
    "kind": "judge",
    "provider": "openai_compatible",
    "model": "llama3",
    "base_url": "http://localhost:11434",
    "api_key": "ollama"
  }
}

# Optional overrides (defaults shown):
PROMPTS_FILE=prompts.txt
SYSTEM_PROMPT_FILE=system_prompt.txt
MAX_SYSTEM_LINES=20
MAX_SYSTEM_TOKENS_APPROX=300
